<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Vis & Society Assignment 3</title>
    <link
      rel="stylesheet"
      href="https://vis-society.github.io/assignments/report.css"
    />
  </head>

  <body>
    <header>
      <h1>
        <small>Assignment 4</small>
        Persuasive or Deceptive Visualization?
      </h1>

      <p><strong>Belinda Lin</strong> — <em>belindal@mit.edu</em></p>
    </header>

    <main>
      <h2>Proposition: The NYPD disproportionately receives complaints from Black individuals, suggesting the presence of racial bias in policing.</h2>

      <section>
        <h3>FOR the Proposition</h3>

        <figure>
          <img src="../images/piee.png" alt="" width="100%"/>
          <figcaption>
            This visualization illustrates the distribution of NYPD complaints by ethnicity across NYC, showing the proportion of total complaints attributed to each group. The size of each section reflects the percentage of overall complaints, enabling a direct comparison of how different ethnic groups interact with the complaint system. However, this visualization is deceptive because it only includes precincts where Black complaints are the majority, excluding other areas that may have more balanced distributions. This selective filtering amplifies the appearance of racial disparities without providing a full view of complaint patterns citywide.  </figcaption>
        </figure>

        <p>Design Decisions and Rationale:</p>

        <ul>
          <li>
			Using a Pie Chart to Emphasize Proportions — Score: 1 (Mostly Earnest)
            <ul>
              <li>
                Rationale: A pie chart visually communicates proportional differences in complaint rates between ethnic groups, making disparities in complaint filings immediately clear.
			  </li>
              <li>
				Persuasive Effect: Pie charts are intuitive for general audiences, making it easy to compare the complaint shares between groups.
			 </li>
			  <li>What Worked: The clear divisions and color contrast make the visualization highly readable.
				</li>	<li>What Didn’t Work: Pie charts lack precise numerical comparison, making it harder to analyze small differences.
					</li>
						<li>
							Alternative Considered: A bar chart would allow for a more detailed numerical comparison but would be less intuitive at a glance.
						   </li>
            </ul>
          </li>
        </ul>
		<ul>
			<li>
				Filtering Data to Only Include Precincts with High Black Complaint Rates -- Score: -2 (Fully Deceptive)
			  <ul>
				<li>
				  Rationale:
				  This visualization only includes precincts where Black complaint rates are significantly higher, completely removing precincts where complaints are more evenly distributed among ethnic groups.
				  By excluding precincts with lower Black complaint rates, the visualization amplifies the appearance of racial disparities without showing the full dataset.
 </li>
				<li>
				  Persuasive Effect:
  
				  Viewers only see precincts where Black complaints are dominant, which could mislead them into believing that all precincts follow this pattern.
This strongly supports the proposition but at the cost of fairness, as it selectively removes data that might contradict the narrative.
</li>
				<li>What Worked:
  
					Effectively emphasizes racial disparities in complaints by only showing cases where Black individuals file significantly more complaints.
					<li>What Didn’t Work:
  
						Misleading by omission—viewers are not given the full picture, meaning they might overestimate the degree of disparity across all precincts. </li>
						 <li>
					  Alternative Considered:
  
					  Including all precincts for a more balanced comparison, but that would reduce the persuasive impact of the argument.
					</li>
			  </ul>
			</li>
		  </ul>
  
        <ul>
          <li>
            Transforming Raw Complaint Counts into Percentages -- 
Score: 2 (Fully Earnest)
            <ul>
              <li>
				Rationale: Instead of displaying raw complaint counts, I transformed the data into percentages to better compare complaint rates across racial groups. Since precincts vary in size, raw numbers alone would not provide a fair comparison.  </li>
              <li>
                Persuasive Effect: Normalizing complaints as percentages ensures that differences in precinct sizes do not mislead viewers into thinking that larger precincts necessarily have more complaints. This transformation makes disparities in complaint rates more meaningful.  </li>
			  <li>
				What Worked: This allows for an apples-to-apples comparison of complaint distribution, making the visualization more informative.  </li>
			  <li>
				What Didn’t Work: Some viewers may misinterpret percentages as absolute numbers if they do not understand how normalization works.  </li>
              <li>
                Alternative Considered: Using raw complaint counts, but that would have unfairly biased the visualization toward more populous precincts.    </li>
            </ul>
          </li>
        </ul>

        <ul>
          <li>
            Color-Coding Ethnic Groups for Clearer Differentiation -- Score: 1.5 (Mostly
            Earnest)

            <ul>
              <li>
                Rationale: Assigning a distinct color for each ethnic group
                ensures clear differentiation and prevents confusion between
                categories. 
              </li>
              <li>
                Persuasive Effect:

Improves clarity by ensuring each ethnicity is immediately recognizable.
Draws attention to differences in complaint distributions across NYC.
              </li>
			  <li>
				What Worked:

The color coding prevents confusion and enhances pattern recognition.
			  </li>
			  <li>
				What did not work: Some colorblind viewers may struggle to differentiate colors, though accessibility-friendly palettes were considered.
			  </li>
              <li>
                Alternatives Considered: A monochrome scheme was tested, but it made it harder to compare ethnic distributions effectively.
              </li>
            </ul> </ul>
			<ul>
				<li>
					Filtering Out People with Unknown Ethnicities -- Score: -0.5 (Slightly Deceptive)
	  
				  <ul>
					<li>
						Rationale: People with unknown ethnicities were removed from the dataset to focus on identifiable racial groups. However, this exclusion also removes potentially meaningful data, as these complaints may not be evenly distributed across ethnicities.	</li>
					<li>
						Persuasive Effect: The omission ensures that the visualization remains clear and focused on racial disparities without distraction.
					</li>
					<li> 
						What Worked: The graph appears cleaner and more interpretable.
					</li>
					<li>
						What Didn’t Work: By removing the "Unknown" category, some complaints are unaccounted for, possibly altering the perceived proportions of the remaining groups.
						</li>
					<li>
						Alternative Considered: Keeping the “Unknown” category but displaying it separately could have provided more transparency without cluttering the visualization.
					</li>
				  </ul> </ul>
				  
          
        </ul>
      </section>

      <section>
        <h3>AGAINST the Proposition</h3>

        <figure>
          <img src="../images/output (2).png" alt="" width="100%"/>
          <figcaption>
            This chart compares actual (green) vs. expected (orange) complaint rates
            by ethnicity, highlighting disparities where actual complaints
            exceed expectations.
          </figcaption>
        </figure>

        <p>Design Decisions and Rationale:</p>

        <ul>
			<li>
				Transforming Data by Calculating Expected Complaint Rates Based on Population -- Score: 2 (Fully Earnest)
			  <ul>
				<li>
					Rationale: Instead of displaying raw complaint counts, I transformed the data into percentages to allow for an accurate comparison across different ethnic groups. Since precinct sizes vary, raw numbers alone would not fairly represent differences in complaint rates.
				</li>
				<li>
					Persuasive Effect: This transformation ensures that differences in precinct sizes do not skew the perception of complaints. It helps make disparities in complaint rates more meaningful rather than simply showing absolute complaint numbers.
							</li>
				<li>
					What Worked: This normalization enables an effective side-by-side comparison of complaint distribution, preventing large precincts from appearing disproportionately problematic.
								<li>What Didn’t Work: Some viewers might misinterpret percentages as absolute numbers without additional clarification.				
						<li>
							Alternative Considered: Using raw complaint counts, but that would have made the visualization less fair due to varying precinct sizes.
						</li>
			  </ul>
			</li>
		  </ul>
		  <ul>
			<li>
			  Using Bar Charts for Comparison -- Score: 2 (Fully Earnest)
			  <ul>
				<li>
					Rationale:

					A bar chart is an intuitive way to compare actual vs. expected complaint rates.
					The side-by-side bars make disparities immediately visible, helping viewers quickly identify which groups file more or fewer complaints than expected.
				</li>
				<li>
					Persuasive Effect: Bars are easy to compare at a glance, making it simple to detect differences in complaint rates between racial groups.
					</li>
				<li>What Worked:

					Bars clearly show where actual complaints exceed or fall below expectations, making the disparities obvious.</li>
					<li>What Didn’t Work:
  
						

						Small differences might not be as noticeable compared to other visualization types like a scatter plot.</li>
				  <li>
					Alternative Considered:

					A scatter plot was considered, but it would require more interpretation effort from the viewer.</li>
			  </ul>
			</li>
		  </ul>
		  <ul>
			<li>
				Color Choices: Green for Actual Complaints, Orange for Expected Complaints — Score: 1.5 (Mostly Earnest)
				  <ul>
				<li>
					Rationale: Green represents actual complaint rates, while orange represents expected complaint rates. This color scheme makes it easy to differentiate between actual and expected complaints while keeping the visualization neutral in tone.
				</li>
				<li>
					Persuasive Effect: The color contrast improves clarity without implying a bias in the data.
				</li>
				<li>What Worked: The visual contrast makes the actual and expected complaint rates distinct, improving readability.
						<li>What Didn’t Work: Some viewers might associate green with positive outcomes and orange with warnings, which could unintentionally influence perception.
								</li>
				  <li>
					Alternative Considered: Using a monochrome gradient, but that would make distinguishing between actual and expected complaints more difficult.
				</li>
			  </ul>
			</li>
		  </ul>
		  <ul>
			<li>
				Comparing Actual vs. Expected Complaint Rates — Score: 2 (Fully Earnest)
				  <ul>
				<li>
					Rationale: The graph includes two bars for each ethnicity—one for the actual complaint rate and one for the expected complaint rate based on population proportions. This comparison highlights disparities between reported complaints and what would be expected if complaints were proportional to demographic representation.
					</li>
				<li>
					Persuasive Effect: This direct comparison ensures that disparities are contextualized rather than left to interpretation. The chart allows viewers to immediately identify which groups are over- or underrepresented in complaints.
				</li>
				<li>What Worked: The use of two bars per category makes it easy to identify the differences between actual and expected complaints.
									<li>WWhat Didn’t Work: Some viewers may not immediately understand how the expected complaint rate was calculated, requiring explanation.
												  <li>
													Alternative Considered: Using only actual complaint rates, but that would fail to contextualize the data properly.
																</li>
			  </ul>
			</li>
		  </ul>
		  <ul>
			<li>
				Filtering Out People with Unknown Ethnicities — Score: -0.5 (Slightly Deceptive)
				  <ul>
				<li>
					Rationale: Complaints from individuals whose ethnicity was not recorded were excluded to focus on identifiable racial groups. However, this exclusion removes potentially meaningful data, as these complaints may not be evenly distributed across ethnicities.
							</li>
				<li>
					Persuasive Effect: The omission ensures that the visualization remains clear and focused on racial disparities without distraction
				</li>
				<li>What Worked: The graph appears cleaner and more interpretable without an "Unknown" category.
								<li>What Didn’t Work: By removing the "Unknown" category, some complaints are unaccounted for, possibly altering the perceived proportions of the remaining groups.
												 <li>
													Alternative Considered: Keeping the “Unknown” category but displaying it separately could have provided more transparency without cluttering the visualization.
												</li>
			  </ul>
			</li>
		  </ul>
      </section>

      <section>
        <h2>Final Reflection</h2>

        <p>The design process for these visualizations revealed the nuanced balance between ethical analysis and persuasive storytelling in data visualization. One of the more straightforward aspects was transforming raw complaint counts into percentages, which provided a fairer comparison across ethnic groups while preventing large precincts from appearing disproportionately problematic. Choosing colors to differentiate categories and structuring the visualizations for clarity were also relatively simple decisions. However, a more challenging aspect was deciding how much data to include or exclude—specifically, the decision to filter precincts with high Black complaint rates or to remove people with unknown ethnicities. These choices had significant implications for how the data was perceived and, in some cases, introduced bias by omission.

			This project underscored the importance of transparency in ethical data visualization. Ethical analysis does not mean avoiding all persuasive techniques; rather, it involves ensuring that any transformations, exclusions, or visual design choices do not mislead the viewer. The boundary between acceptable persuasive choices and misleading ones lies in whether the visualization fairly represents the underlying data without distorting its meaning. While simplification is often necessary for clarity, omitting contradictory data, selectively filtering results, or using suggestive color schemes can manipulate perception. Ethical visualization, therefore, requires making these decisions explicit and justifiable, allowing the audience to critically interpret the findings rather than being guided toward a predetermined conclusion.</p>
			
			
			
			
			
			
</p>			 </section>
    </main>
  </body>
</html>
